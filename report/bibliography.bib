@inproceedings{7780677,
  title = {Rethinking the Inception Architecture for Computer Vision},
  booktitle = {2016 {{IEEE}} Conference on Computer Vision and Pattern Recognition ({{CVPR}})},
  author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  date = {2016},
  pages = {2818--2826},
  doi = {10.1109/CVPR.2016.308},
  file = {/home/yasser/.local/share/Zotero/storage/T89IDTHL/szegedy2016.pdf.pdf}
}

@misc{alamFloodDetectionTwitter2020,
  title = {Flood {{Detection}} via {{Twitter Streams}} Using {{Textual}} and {{Visual Features}}},
  author = {Alam, Firoj and Hassan, Zohaib and Ahmad, Kashif and Gul, Asma and Reiglar, Michael and Conci, Nicola and AL-Fuqaha, Ala},
  date = {2020-11-30},
  number = {arXiv:2011.14944},
  eprint = {2011.14944},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2011.14944},
  url = {http://arxiv.org/abs/2011.14944},
  urldate = {2022-10-18},
  abstract = {The paper presents our proposed solutions for the MediaEval 2020 Flood-Related Multimedia Task, which aims to analyze and detect flooding events in multimedia content shared over Twitter. In total, we proposed four different solutions including a multi-modal solution combining textual and visual information for the mandatory run, and three single modal image and text-based solutions as optional runs. In the multimodal method, we rely on a supervised multimodal bitransformer model that combines textual and visual features in an early fusion, achieving a micro F1-score of .859 on the development data set. For the text-based flood events detection, we use a transformer network (i.e., pretrained Italian BERT model) achieving an F1-score of .853. For image-based solutions, we employed multiple deep models, pre-trained on both, the ImageNet and places data sets, individually and combined in an early fusion achieving F1-scores of .816 and .805 on the development set, respectively.},
  archiveprefix = {arXiv},
  version = {1},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/yasser/.local/share/Zotero/storage/GCXPUNJJ/Alam et al. - 2020 - Flood Detection via Twitter Streams using Textual .pdf;/home/yasser/.local/share/Zotero/storage/R8HDIXLZ/2011.html}
}

@article{argamon-engelsonCommitteeBasedSampleSelection1999,
  title = {Committee-{{Based Sample Selection}} for {{Probabilistic Classifiers}}},
  author = {Argamon-Engelson, S. and Dagan, I.},
  date = {1999-11-15},
  journaltitle = {Journal of Artificial Intelligence Research},
  shortjournal = {jair},
  volume = {11},
  eprint = {1106.0220},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {335--360},
  issn = {1076-9757},
  doi = {10.1613/jair.612},
  url = {http://arxiv.org/abs/1106.0220},
  urldate = {2023-01-19},
  abstract = {In many real-world learning tasks, it is expensive to acquire a sufficient number of labeled examples for training. This paper investigates methods for reducing annotation cost by `sample selection'. In this approach, during training the learning program examines many unlabeled examples and selects for labeling only those that are most informative at each stage. This avoids redundantly labeling examples that contribute little new information. Our work follows on previous research on Query By Committee, extending the committee-based paradigm to the context of probabilistic classification. We describe a family of empirical methods for committee-based sample selection in probabilistic classification models, which evaluate the informativeness of an example by measuring the degree of disagreement between several model variants. These variants (the committee) are drawn randomly from a probability distribution conditioned by the training set labeled so far. The method was applied to the real-world natural language processing task of stochastic part-of-speech tagging. We find that all variants of the method achieve a significant reduction in annotation cost, although their computational efficiency differs. In particular, the simplest variant, a two member committee with no parameters to tune, gives excellent results. We also show that sample selection yields a significant reduction in the size of the model used by the tagger.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/yasser/.local/share/Zotero/storage/66UUN5F6/Argamon-Engelson and Dagan - 1999 - Committee-Based Sample Selection for Probabilistic.pdf;/home/yasser/.local/share/Zotero/storage/5HPBGNVW/1106.html}
}

@article{barkerDevelopmentNationalscaleRealtime2019,
  title = {Development of a National-Scale Real-Time {{Twitter}} Data Mining Pipeline for Social Geodata on the Potential Impacts of Flooding on Communities},
  author = {Barker, J.L.P. and Macleod, C.J.A.},
  date = {2019-05},
  journaltitle = {Environmental Modelling \& Software},
  shortjournal = {Environmental Modelling \& Software},
  volume = {115},
  pages = {213--227},
  issn = {13648152},
  doi = {10.1016/j.envsoft.2018.11.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S136481521830094X},
  urldate = {2022-09-07},
  langid = {english},
  file = {/home/yasser/.local/share/Zotero/storage/L6PJW7XH/624933f4807daf2683e1bc31a1d29d14.pdf.pdf;/home/yasser/.local/share/Zotero/storage/M8HXSB29/Barker and Macleod - 2019 - Development of a national-scale real-time Twitter .pdf}
}

@inreference{contributorsEarlyWarningSystem2022,
  title = {Early Warning System},
  booktitle = {Wikipedia},
  author = {{contributors}, Wikipedia},
  year = {10/30/2022, 06:41:00 AM},
  edition = {1119015319},
  publisher = {{Wikipedia, The Free Encyclopedia}},
  url = {https://en.wikipedia.org/w/index.php?title=Early_warning_system&oldid=1119015319},
  urldate = {2022-11-17}
}

@online{daviesSwedenFlashFloods2021,
  title = {Sweden – {{Flash Floods}} in {{Dalarna}} and {{Gävleborg After Record Rainfall}}},
  author = {Davies, Richard},
  date = {2021-08-19},
  url = {https://floodlist.com/europe/central-sweden-floods-august-2021},
  urldate = {2022-11-17},
  organization = {{FloodList}}
}

@article{debruijnGlobalDatabaseHistoric2019b,
  title = {A Global Database of Historic and Real-Time Flood Events Based on Social Media},
  author = {de Bruijn, Jens A. and de Moel, Hans and Jongman, Brenden and de Ruiter, Marleen C. and Wagemaker, Jurjen and Aerts, Jeroen C. J. H.},
  options = {useprefix=true},
  date = {2019-12-09},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {6},
  number = {1},
  pages = {311},
  publisher = {{Nature Publishing Group}},
  issn = {2052-4463},
  doi = {10.1038/s41597-019-0326-9},
  url = {https://www.nature.com/articles/s41597-019-0326-9},
  urldate = {2022-10-04},
  abstract = {Early event detection and response can significantly reduce the societal impact of floods. Currently, early warning systems rely on gauges, radar data, models and informal local sources. However, the scope and reliability of these systems are limited. Recently, the use of social media for detecting disasters has shown promising results, especially for earthquakes. Here, we present a new database for detecting floods in real-time on a global scale using Twitter. The method was developed using 88 million tweets, from which we derived over 10,000 flood events (i.e., flooding occurring in a country or first order administrative subdivision) across 176 countries in 11 languages in just over four years. Using strict parameters, validation shows that approximately 90\% of the events were correctly detected. In countries where the first official language is included, our algorithm detected 63\% of events in NatCatSERVICE disaster database at admin 1 level. Moreover, a large number of flood events not included in NatCatSERVICE were detected. All results are publicly available on www.globalfloodmonitor.org.},
  issue = {1},
  langid = {english},
  keywords = {Geography,Hydrology,Natural hazards},
  file = {/home/yasser/.local/share/Zotero/storage/GI8X8ZME/10.1038@s41597-019-0326-9.pdf.pdf;/home/yasser/.local/share/Zotero/storage/V328EEK8/de Bruijn et al. - 2019 - A global database of historic and real-time flood .pdf;/home/yasser/.local/share/Zotero/storage/AZU2XD4U/s41597-019-0326-9.html}
}

@article{debruijnImprovingClassificationFlood2020,
  title = {Improving the Classification of Flood Tweets with Contextual Hydrological Information in a Multimodal Neural Network},
  author = {de Bruijn, Jens A. and de Moel, Hans and Weerts, Albrecht H. and de Ruiter, Marleen C. and Basar, Erkan and Eilander, Dirk and Aerts, Jeroen C.J.H.},
  options = {useprefix=true},
  date = {2020-07},
  journaltitle = {Computers \& Geosciences},
  shortjournal = {Computers \& Geosciences},
  volume = {140},
  pages = {104485},
  issn = {00983004},
  doi = {10.1016/j.cageo.2020.104485},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0098300419308106},
  urldate = {2022-11-28},
  langid = {english},
  file = {/home/yasser/.local/share/Zotero/storage/92LDPBPZ/10.1016@j.cageo.2020.104485.pdf.pdf;/home/yasser/.local/share/Zotero/storage/KDGMMHIZ/de Bruijn et al. - 2020 - Improving the classification of flood tweets with .pdf}
}

@article{debruijnTAGGSGroupingTweets2017,
  title = {{{TAGGS}}: {{Grouping Tweets}} to {{Improve Global Geoparsing}} for {{Disaster Response}}},
  shorttitle = {{{TAGGS}}},
  author = {de Bruijn, Jens A. and de Moel, Hans and Jongman, Brenden and Wagemaker, Jurjen and Aerts, Jeroen C. J. H.},
  options = {useprefix=true},
  date = {2017-12-26},
  journaltitle = {Journal of Geovisualization and Spatial Analysis},
  shortjournal = {J geovis spat anal},
  volume = {2},
  number = {1},
  pages = {2},
  issn = {2509-8829},
  doi = {10.1007/s41651-017-0010-6},
  url = {https://doi.org/10.1007/s41651-017-0010-6},
  urldate = {2022-10-04},
  abstract = {Timely and accurate information about ongoing events are crucial for relief organizations seeking to effectively respond to disasters. Recently, social media platforms, especially Twitter, have gained traction as a novel source of information on disaster events. Unfortunately, geographical information is rarely attached to tweets, which hinders the use of Twitter for geographical applications. As a solution, geoparsing algorithms extract and can locate geographical locations referenced in a tweet’s text. This paper describes TAGGS, a new algorithm that enhances location disambiguation by employing both metadata and the contextual spatial information of groups of tweets referencing the same location regarding a specific disaster type. Validation demonstrated that TAGGS approximately attains a recall of 0.82 and precision of 0.91. Without lowering precision, this roughly doubles the number of correctly found administrative subdivisions and cities, towns, and villages as compared to individual geoparsing. We applied TAGGS to 55.1 million flood-related tweets in 12 languages, collected over 3~years. We found 19.2 million tweets mentioning one or more flood locations, which can be towns (11.2 million), administrative subdivisions (5.1 million), or countries (4.6 million). In the future, TAGGS could form the basis for a global event detection system.},
  langid = {english},
  keywords = {Disaster response,Floods,Geocoding,Geolocation,Geoparsing,Geotagging,Twitter},
  file = {/home/yasser/.local/share/Zotero/storage/FJ63FU6L/debruijn2017.pdf.pdf;/home/yasser/.local/share/Zotero/storage/R2CZEM87/de Bruijn et al. - 2017 - TAGGS Grouping Tweets to Improve Global Geoparsin.pdf}
}

@misc{devlinBERTPretrainingDeep2019,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  date = {2019-05-24},
  number = {arXiv:1810.04805},
  eprint = {1810.04805},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1810.04805},
  url = {http://arxiv.org/abs/1810.04805},
  urldate = {2022-11-26},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/home/yasser/.local/share/Zotero/storage/JM92IKGC/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf;/home/yasser/.local/share/Zotero/storage/N7JXBGYJ/1810.html}
}

@misc{DVN/T3ZFMR_2019,
  title = {Flood Tweet {{IDs}} (Multilingual)},
  author = {{de}, Jens},
  date = {2019},
  publisher = {{Harvard Dataverse}},
  doi = {10.7910/DVN/T3ZFMR},
  url = {https://doi.org/10.7910/DVN/T3ZFMR},
  version = {V2}
}

@misc{enwiki:1123031029,
  title = {Tf–Idf — {{Wikipedia}}, the Free Encyclopedia},
  author = {{Wikipedia contributors}},
  date = {2022},
  url = {https://en.wikipedia.org/w/index.php?title=Tf%E2%80%93idf&oldid=1123031029}
}

@article{fengExtractionPluvialFlood2018,
  title = {Extraction of {{Pluvial Flood Relevant Volunteered Geographic Information}} ({{VGI}}) by {{Deep Learning}} from {{User Generated Texts}} and {{Photos}}},
  author = {Feng, Yu and Sester, Monika},
  date = {2018-02},
  journaltitle = {ISPRS International Journal of Geo-Information},
  volume = {7},
  number = {2},
  pages = {39},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2220-9964},
  doi = {10.3390/ijgi7020039},
  url = {https://www.mdpi.com/2220-9964/7/2/39},
  urldate = {2022-09-07},
  abstract = {In recent years, pluvial floods caused by extreme rainfall events have occurred frequently. Especially in urban areas, they lead to serious damages and endanger the citizens’ safety. Therefore, real-time information about such events is desirable. With the increasing popularity of social media platforms, such as Twitter or Instagram, information provided by voluntary users becomes a valuable source for emergency response. Many applications have been built for disaster detection and flood mapping using crowdsourcing. Most of the applications so far have merely used keyword filtering or classical language processing methods to identify disaster relevant documents based on user generated texts. As the reliability of social media information is often under criticism, the precision of information retrieval plays a significant role for further analyses. Thus, in this paper, high quality eyewitnesses of rainfall and flooding events are retrieved from social media by applying deep learning approaches on user generated texts and photos. Subsequently, events are detected through spatiotemporal clustering and visualized together with these high quality eyewitnesses in a web map application. Analyses and case studies are conducted during flooding events in Paris, London and Berlin.},
  issue = {2},
  langid = {english},
  keywords = {convolutional neural network,crowdsourcing,flood mapping,multimedia information retrieval,social media,transfer learning,volunteered geographic information,word embedding},
  file = {/home/yasser/.local/share/Zotero/storage/IGJQIZ5V/Feng and Sester - 2018 - Extraction of Pluvial Flood Relevant Volunteered G.pdf;/home/yasser/.local/share/Zotero/storage/RQITW64L/extraction-of-pluvial-flood-relevant-volunteered-geographic-info-2018.pdf.pdf;/home/yasser/.local/share/Zotero/storage/CX9YIYBR/39.html}
}

@online{Floodlist2021,
  title = {Floodlist},
  date = {2021-08-19},
  url = {https://floodlist.com/europe/central-sweden-floods-august-2021},
  urldate = {2022-11-17},
  organization = {{FloodList}}
}

@incollection{grunder-fahrerHowSocialMedia2018,
  title = {How {{Social Media Text Analysis Can Inform Disaster Management}}},
  booktitle = {Language {{Technologies}} for the {{Challenges}} of the {{Digital Age}}},
  author = {Gründer-Fahrer, Sabine and Schlaf, Antje and Wustmann, Sebastian},
  editor = {Rehm, Georg and Declerck, Thierry},
  date = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {10713},
  pages = {199--207},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-73706-5_17},
  url = {http://link.springer.com/10.1007/978-3-319-73706-5_17},
  urldate = {2023-01-17},
  isbn = {978-3-319-73705-8 978-3-319-73706-5},
  file = {/home/yasser/.local/share/Zotero/storage/6XBJBKI2/Gründer-Fahrer et al. - 2018 - How Social Media Text Analysis Can Inform Disaster.pdf}
}

@misc{heDeepResidualLearning2015,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2015-12-10},
  number = {arXiv:1512.03385},
  eprint = {1512.03385},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1512.03385},
  url = {http://arxiv.org/abs/1512.03385},
  urldate = {2023-01-04},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/yasser/.local/share/Zotero/storage/J4BXTTM7/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf;/home/yasser/.local/share/Zotero/storage/A3WBFTQT/1512.html}
}

@misc{howardUniversalLanguageModel2018,
  title = {Universal {{Language Model Fine-tuning}} for {{Text Classification}}},
  author = {Howard, Jeremy and Ruder, Sebastian},
  date = {2018-05-23},
  number = {arXiv:1801.06146},
  eprint = {1801.06146},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1801.06146},
  url = {http://arxiv.org/abs/1801.06146},
  urldate = {2023-01-04},
  abstract = {Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24\% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/yasser/.local/share/Zotero/storage/B9PGQP76/Howard and Ruder - 2018 - Universal Language Model Fine-tuning for Text Clas.pdf;/home/yasser/.local/share/Zotero/storage/I37I6EWF/1801.html}
}

@misc{huangDenselyConnectedConvolutional2018,
  title = {Densely {{Connected Convolutional Networks}}},
  author = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
  options = {useprefix=true},
  date = {2018-01-28},
  number = {arXiv:1608.06993},
  eprint = {1608.06993},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1608.06993},
  url = {http://arxiv.org/abs/1608.06993},
  urldate = {2023-01-04},
  abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet .},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/yasser/.local/share/Zotero/storage/LXGZHNN9/Huang et al. - 2018 - Densely Connected Convolutional Networks.pdf;/home/yasser/.local/share/Zotero/storage/RADBXFVF/1608.html}
}

@misc{huLocationReferenceRecognition2022a,
  title = {Location Reference Recognition from Texts: {{A}} Survey and Comparison},
  shorttitle = {Location Reference Recognition from Texts},
  author = {Hu, Xuke and Zhou, Zhiyong and Li, Hao and Hu, Yingjie and Gu, Fuqiang and Kersten, Jens and Fan, Hongchao and Klan, Friederike},
  date = {2022-07-04},
  number = {arXiv:2207.01683},
  eprint = {2207.01683},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2207.01683},
  url = {http://arxiv.org/abs/2207.01683},
  urldate = {2022-10-04},
  abstract = {A vast amount of location information exists in unstructured texts, such as social media posts, news stories, scientific articles, web pages, travel blogs, and historical archives. Geoparsing refers to the process of recognizing location references from texts and identifying their geospatial representations. While geoparsing can benefit many domains, a summary of the specific applications is still missing. Further, there lacks a comprehensive review and comparison of existing approaches for location reference recognition, which is the first and a core step of geoparsing. To fill these research gaps, this review first summarizes seven typical application domains of geoparsing: geographic information retrieval, disaster management, disease surveillance, traffic management, spatial humanities, tourism management, and crime management. We then review existing approaches for location reference recognition by categorizing these approaches into four groups based on their underlying functional principle: rule-based, gazetteer matching-based, statistical learning-based, and hybrid approaches. Next, we thoroughly evaluate the correctness and computational efficiency of the 27 most widely used approaches for location reference recognition based on 26 public datasets with different types of texts (e.g., social media posts and news stories) containing 39,736 location references across the world. Results from this thorough evaluation can help inform future methodological developments for location reference recognition, and can help guide the selection of proper approaches based on application needs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,H.3.3,I.2.7,Natural language processing},
  file = {/home/yasser/.local/share/Zotero/storage/M6MWPIQH/Hu et al. - 2022 - Location reference recognition from texts A surve.pdf;/home/yasser/.local/share/Zotero/storage/M5HTZJC7/2207.html}
}

@inproceedings{inproceedings,
  title = {How Much Data Do You Need? {{Twitter}} Decahose Data Analysis},
  author = {Li, Quanzhi and Shah, Sameena and Thomas, Merine and Anderson, Kajsa and Liu, Xiaomo and Nourbakhsh, Armineh and Fang, Rui},
  date = {2016-07}
}

@inproceedings{jayasiriwardeneKeywordExtractionTweets2020,
  title = {Keyword Extraction from {{Tweets}} Using {{NLP}} Tools for Collecting Relevant News},
  booktitle = {2020 {{International Research Conference}} on {{Smart Computing}} and {{Systems Engineering}} ({{SCSE}})},
  author = {Jayasiriwardene, Thiruni D. and Ganegoda, Gamage Upeksha},
  date = {2020-09},
  pages = {129--135},
  issn = {2613-8662},
  doi = {10.1109/SCSE49731.2020.9313024},
  abstract = {Keywords play a major role in representing the gist of a document. Therefore, a lot of Natural Language processing tools have been implemented to identify keywords in both structured and unstructured texts. Text that appears in social media platforms such as twitter is mostly unstructured because of the character limitation. Consequently, a lot of short terms and symbols such as emoticons and URLs are included in tweets. Keyword extraction from grammatically ambiguous text is not easy compared to structured text since it is hard to rely on the linguistic features in unstructured texts. But when it comes to news on twitter, it may contain somewhat structured text than informal text does but it depends on the tweeter, the person who posts the tweet. In this paper, a methodology is proposed to extract keywords from a given tweet to retrieve relevant news that has been posted on twitter, for fake news detection. The intention of extracting keywords is to find more related news efficiently and effectively. For this approach, a corpus that contains tweet texts from different domains is built in order to make this approach more generic instead of making it a domain-specific approach. In fact, the Stanford Core NLP tool kit, Wordnet linguistic database and statistical method are used for extracting keywords from a tweet. For the system evaluation, the Turing test which has human intervention is used. The system was able to acquire an accuracy of 67.6\% according to the evaluation conducted.},
  eventtitle = {2020 {{International Research Conference}} on {{Smart Computing}} and {{Systems Engineering}} ({{SCSE}})},
  keywords = {Blogs,Data mining,Feature extraction,Hidden Markov models,Linguistics,Named Entity Recognition (NER),Natural Language Processing (NLP),Part of speech tagging,Social networking (online),Stanford Core NLP,Tools,Wordnet corpus},
  file = {/home/yasser/.local/share/Zotero/storage/RXB6QMGM/jayasiriwardene2020.pdf.pdf;/home/yasser/.local/share/Zotero/storage/4MU8Y22B/9313024.html}
}

@inproceedings{jingIntegrationTextImage2016,
  title = {Integration of Text and Image Analysis for Flood Event Image Recognition},
  booktitle = {2016 27th {{Irish Signals}} and {{Systems Conference}} ({{ISSC}})},
  author = {Jing, Min and Scotney, Bryan W. and Coleman, Sonya A. and McGinnity, Martin T. and Zhang, Xiubo and Kelly, Stephen and Ahmad, Khurshid and Schlaf, Antje and Grunder-Fahrer, Sabine and Heyer, Gerhard},
  date = {2016-06},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Londonderry, United Kingdom}},
  doi = {10.1109/ISSC.2016.7528454},
  url = {http://ieeexplore.ieee.org/document/7528454/},
  urldate = {2022-12-15},
  eventtitle = {2016 27th {{Irish Signals}} and {{Systems Conference}} ({{ISSC}})},
  isbn = {978-1-5090-3409-3},
  file = {/home/yasser/.local/share/Zotero/storage/ND5IIH4Q/jing2016.pdf.pdf;/home/yasser/.local/share/Zotero/storage/XNJLX4CS/Jing et al. - 2016 - Integration of text and image analysis for flood e.pdf}
}

@article{krizhevskyImageNetClassificationDeep2017,
  title = {{{ImageNet}} Classification with Deep Convolutional Neural Networks},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, zz},
  date = {2017-05-24},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {60},
  number = {6},
  pages = {84--90},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3065386},
  url = {https://dl.acm.org/doi/10.1145/3065386},
  urldate = {2022-12-15},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  langid = {english},
  file = {/home/yasser/.local/share/Zotero/storage/H9N47YQL/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf;/home/yasser/.local/share/Zotero/storage/Y662K79L/krizhevsky2017.pdf.pdf}
}

@misc{leDistributedRepresentationsSentences2014,
  title = {Distributed {{Representations}} of {{Sentences}} and {{Documents}}},
  author = {Le, Quoc V. and Mikolov, Tomas},
  date = {2014-05-22},
  number = {arXiv:1405.4053},
  eprint = {1405.4053},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1405.4053},
  url = {http://arxiv.org/abs/1405.4053},
  urldate = {2022-12-30},
  abstract = {Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/yasser/.local/share/Zotero/storage/N6N78HGR/Le and Mikolov - 2014 - Distributed Representations of Sentences and Docum.pdf;/home/yasser/.local/share/Zotero/storage/FSCEMNF7/1405.html}
}

@article{liDisasterResponseAided2018,
  title = {Disaster Response Aided by Tweet Classification with a Domain Adaptation Approach},
  author = {Li, Hongmin and Caragea, Doina and Caragea, Cornelia and Herndon, Nic},
  date = {2018-03},
  journaltitle = {Journal of Contingencies and Crisis Management},
  shortjournal = {J Contingencies and Crisis Management},
  volume = {26},
  number = {1},
  pages = {16--27},
  issn = {0966-0879, 1468-5973},
  doi = {10.1111/1468-5973.12194},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/1468-5973.12194},
  urldate = {2022-09-11},
  langid = {english},
  file = {/home/yasser/.local/share/Zotero/storage/7E96653T/Li et al. - 2018 - Disaster response aided by tweet classification wi.pdf;/home/yasser/.local/share/Zotero/storage/VVVSFTWH/19af78088e2c741c3be86a7666bb4aeb.pdf.pdf}
}

@article{lopez2017multi,
  title = {Multi-Modal Deep Learning Approach for Flood Detection.},
  author = {Lopez-Fuentes, Laura and van de Weijer, Joost and Bolanos, Marc and Skinnemoen, Harald},
  options = {useprefix=true},
  date = {2017},
  journaltitle = {MediaEval},
  volume = {17},
  pages = {13--15},
  file = {/home/yasser/.local/share/Zotero/storage/WCNPTYMA/Lopez-Fuentes et al. - 2017 - Multi-modal deep learning approach for flood detec.pdf}
}

@inproceedings{luVisualizingSocialMedia2015,
  title = {Visualizing {{Social Media Sentiment}} in {{Disaster Scenarios}}},
  booktitle = {Proceedings of the 24th {{International Conference}} on {{World Wide Web}}},
  author = {Lu, Yafeng and Hu, Xia and Wang, Feng and Kumar, Shamanth and Liu, Huan and Maciejewski, Ross},
  date = {2015-05-18},
  pages = {1211--1215},
  publisher = {{ACM}},
  location = {{Florence Italy}},
  doi = {10.1145/2740908.2741720},
  url = {https://dl.acm.org/doi/10.1145/2740908.2741720},
  urldate = {2022-12-16},
  eventtitle = {{{WWW}} '15: 24th {{International World Wide Web Conference}}},
  isbn = {978-1-4503-3473-0},
  langid = {english},
  file = {/home/yasser/.local/share/Zotero/storage/NNC72J2W/lu2015.pdf.pdf}
}

@inproceedings{marujoAutomaticKeywordExtraction2015,
  title = {Automatic {{Keyword Extraction}} on {{Twitter}}},
  booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 2: {{Short Papers}})},
  author = {Marujo, Luís and Ling, Wang and Trancoso, Isabel and Dyer, Chris and Black, Alan W. and Gershman, Anatole and Martins de Matos, David and Neto, João and Carbonell, Jaime},
  date = {2015-07},
  pages = {637--643},
  publisher = {{Association for Computational Linguistics}},
  location = {{Beijing, China}},
  doi = {10.3115/v1/P15-2105},
  url = {https://aclanthology.org/P15-2105},
  urldate = {2022-11-27},
  eventtitle = {{{ACL-IJCNLP}} 2015},
  file = {/home/yasser/.local/share/Zotero/storage/4TERVESZ/Marujo et al. - 2015 - Automatic Keyword Extraction on Twitter.pdf}
}

@article{middletonLocationExtractionSocial2018,
  title = {Location {{Extraction}} from {{Social Media}}: {{Geoparsing}}, {{Location Disambiguation}}, and {{Geotagging}}},
  shorttitle = {Location {{Extraction}} from {{Social Media}}},
  author = {Middleton, Stuart E. and Kordopatis-Zilos, Giorgos and Papadopoulos, Symeon and Kompatsiaris, Yiannis},
  date = {2018-06-13},
  journaltitle = {ACM Transactions on Information Systems},
  shortjournal = {ACM Trans. Inf. Syst.},
  volume = {36},
  number = {4},
  pages = {40:1--40:27},
  issn = {1046-8188},
  doi = {10.1145/3202662},
  url = {https://doi.org/10.1145/3202662},
  urldate = {2022-10-19},
  abstract = {Location extraction, also called “toponym extraction,” is a field covering geoparsing, extracting spatial representations from location mentions in text, and geotagging, assigning spatial coordinates to content items. This article evaluates five “best-of-class” location extraction algorithms. We develop a geoparsing algorithm using an OpenStreetMap database, and a geotagging algorithm using a language model constructed from social media tags and multiple gazetteers. Third-party work evaluated includes a DBpedia-based entity recognition and disambiguation approach, a named entity recognition and Geonames gazetteer approach, and a Google Geocoder API approach. We perform two quantitative benchmark evaluations, one geoparsing tweets and one geotagging Flickr posts, to compare all approaches. We also perform a qualitative evaluation recalling top N location mentions from tweets during major news events. The OpenStreetMap approach was best (F1 0.90+) for geoparsing English, and the language model approach was best (F1 0.66) for Turkish. The language model was best (F1@1km 0.49) for the geotagging evaluation. The map database was best (R@20 0.60+) in the qualitative evaluation. We report on strengths, weaknesses, and a detailed failure analysis for the approaches and suggest concrete areas for further research.},
  keywords = {benchmark,disambiguation,geocoding,geoparsing,geotagging,information extraction,location,Location extraction,social media,toponym,toponym extraction},
  file = {/home/yasser/.local/share/Zotero/storage/9FCIE3ZR/Middleton et al. - 2018 - Location Extraction from Social Media Geoparsing,.pdf;/home/yasser/.local/share/Zotero/storage/BUMP7VCS/middleton2018.pdf.pdf}
}

@article{middletonRealTimeCrisisMapping2014,
  title = {Real-{{Time Crisis Mapping}} of {{Natural Disasters Using Social Media}}},
  author = {Middleton, Stuart E. and Middleton, Lee and Modafferi, Stefano},
  date = {2014-03},
  journaltitle = {IEEE Intelligent Systems},
  shortjournal = {IEEE Intell. Syst.},
  volume = {29},
  number = {2},
  pages = {9--17},
  issn = {1541-1672},
  doi = {10.1109/MIS.2013.126},
  url = {http://ieeexplore.ieee.org/document/6692841/},
  urldate = {2022-10-19},
  file = {/home/yasser/.local/share/Zotero/storage/RVA29GGB/middleton2014.pdf.pdf;/home/yasser/.local/share/Zotero/storage/SZNE3Q2K/Middleton et al. - 2014 - Real-Time Crisis Mapping of Natural Disasters Usin.pdf}
}

@misc{mikolovEfficientEstimationWord2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  date = {2013-09-06},
  number = {arXiv:1301.3781},
  eprint = {1301.3781},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1301.3781},
  url = {http://arxiv.org/abs/1301.3781},
  urldate = {2022-12-30},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/home/yasser/.local/share/Zotero/storage/M44B48LU/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf;/home/yasser/.local/share/Zotero/storage/IHJI7QUP/1301.html}
}

@online{nesetAI4ClimateAdaptation,
  type = {University},
  title = {{{AI4ClimateAdaptation}}},
  author = {Neset, Tina},
  url = {https://liu.se/en/research/ai4climateadaptation},
  urldate = {2022-11-18},
  organization = {{Linköping University}}
}

@article{ningPrototypingSocialMedia2020,
  title = {Prototyping a {{Social Media Flooding Photo Screening System Based}} on {{Deep Learning}}},
  author = {Ning, Huan and Li, Zhenlong and Hodgson, Michael E. and Wang, Cuizhen (Susan)},
  date = {2020-02},
  journaltitle = {ISPRS International Journal of Geo-Information},
  volume = {9},
  number = {2},
  pages = {104},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2220-9964},
  doi = {10.3390/ijgi9020104},
  url = {https://www.mdpi.com/2220-9964/9/2/104},
  urldate = {2022-09-11},
  abstract = {This article aims to implement a prototype screening system to identify flooding-related photos from social media. These photos, associated with their geographic locations, can provide free, timely, and reliable visual information about flood events to the decision-makers. This screening system, designed for application to social media images, includes several key modules: tweet/image downloading, flooding photo detection, and a WebGIS application for human verification. In this study, a training dataset of 4800 flooding photos was built based on an iterative method using a convolutional neural network (CNN) developed and trained to detect flooding photos. The system was designed in a way that the CNN can be re-trained by a larger training dataset when more analyst-verified flooding photos are being added to the training set in an iterative manner. The total accuracy of flooding photo detection was 93\% in a balanced test set, and the precision ranges from 46–63\% in the highly imbalanced real-time tweets. The system is plug-in enabled, permitting flexible changes to the classification module. Therefore, the system architecture and key components may be utilized in other types of disaster events, such as wildfires, earthquakes for the damage/impact assessment.},
  issue = {2},
  langid = {english},
  keywords = {deep learning,flood,image,real-time,Twitter},
  file = {/home/yasser/.local/share/Zotero/storage/NRV5N387/10.3390@ijgi9020104.pdf.pdf;/home/yasser/.local/share/Zotero/storage/Z534B9IX/Ning et al. - 2020 - Prototyping a Social Media Flooding Photo Screenin.pdf;/home/yasser/.local/share/Zotero/storage/9EVPMCYL/htm.html}
}

@article{olteanuCrisisLexLexiconCollecting2014,
  title = {{{CrisisLex}}: {{A Lexicon}} for {{Collecting}} and {{Filtering Microblogged Communications}} in {{Crises}}},
  shorttitle = {{{CrisisLex}}},
  author = {Olteanu, Alexandra and Castillo, Carlos and Diaz, Fernando and Vieweg, Sarah},
  date = {2014-05-16},
  journaltitle = {Proceedings of the International AAAI Conference on Web and Social Media},
  shortjournal = {ICWSM},
  volume = {8},
  number = {1},
  pages = {376--385},
  issn = {2334-0770, 2162-3449},
  doi = {10.1609/icwsm.v8i1.14538},
  url = {https://ojs.aaai.org/index.php/ICWSM/article/view/14538},
  urldate = {2022-11-28},
  abstract = {Locating timely, useful information during crises and mass emergencies is critical for those forced to make potentially life-altering decisions. As the use of Twitter to broadcast useful information during such situations becomes more widespread, the problem of finding it becomes more difficult. We describe an approach toward improving the recall in the sampling of Twitter communications that can lead to greater situational awareness during crisis situations. First, we create a lexicon of crisis-related terms that frequently appear in relevant messages posted during different types of crisis situations. Next, we demonstrate how we use the lexicon to automatically identify new terms that describe a given crisis. Finally, we explain how to efficiently query Twitter to extract crisis-related messages during emergency events. In our experiments, using a crisis lexicon leads to substantial improvements in terms of recall when added to a set of crisis-specific keywords manually chosen by experts; it also helps to preserve the original distribution of message types.},
  langid = {english},
  file = {/home/yasser/.local/share/Zotero/storage/T2V2V7TR/Olteanu et al. - 2014 - CrisisLex A Lexicon for Collecting and Filtering .pdf}
}

@article{ordLocalSpatialAutocorrelation2010,
  title = {Local {{Spatial Autocorrelation Statistics}}: {{Distributional Issues}} and an {{Application}}},
  shorttitle = {Local {{Spatial Autocorrelation Statistics}}},
  author = {Ord, J. K. and Getis, Arthur},
  date = {2010-09-03},
  journaltitle = {Geographical Analysis},
  volume = {27},
  number = {4},
  pages = {286--306},
  issn = {00167363},
  doi = {10.1111/j.1538-4632.1995.tb00912.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1538-4632.1995.tb00912.x},
  urldate = {2023-01-08},
  langid = {english},
  file = {/home/yasser/.local/share/Zotero/storage/U3K64AY7/ord2010.pdf.pdf}
}

@inproceedings{palIdentifyingTopicalAuthorities2011,
  title = {Identifying Topical Authorities in Microblogs},
  booktitle = {Proceedings of the Fourth {{ACM}} International Conference on {{Web}} Search and Data Mining},
  author = {Pal, Aditya and Counts, Scott},
  date = {2011-02-09},
  pages = {45--54},
  publisher = {{ACM}},
  location = {{Hong Kong China}},
  doi = {10.1145/1935826.1935843},
  url = {https://dl.acm.org/doi/10.1145/1935826.1935843},
  urldate = {2023-01-19},
  abstract = {Content in microblogging systems such as Twitter is produced by tens to hundreds of millions of users. This diversity is a notable strength, but also presents the challenge of finding the most interesting and authoritative authors for any given topic. To address this, we first propose a set of features for characterizing social media authors, including both nodal and topical metrics. We then show how probabilistic clustering over this feature space, followed by a within-cluster ranking procedure, can yield a final list of top authors for a given topic. We present results across several topics, along with results from a user study confirming that our method finds authors who are significantly more interesting and authoritative than those resulting from several baseline conditions. Additionally our algorithm is computationally feasible in near real-time scenarios making it an attractive alternative for capturing the rapidly changing dynamics of microblogs.},
  eventtitle = {{{WSDM}}'11: {{Fourth ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  isbn = {978-1-4503-0493-1},
  langid = {english},
  file = {/home/yasser/.local/share/Zotero/storage/VLJV7IUY/pal2011.pdf.pdf}
}

@article{perinan-pascualAssessingImpactTweets2020,
  title = {Assessing the {{Impact}} of {{Tweets}} in {{Flood Events}}},
  author = {Periñán-Pascual, Carlos},
  date = {2020-01-01},
  journaltitle = {1st International Workshop on Social Media Analysis for Intelligent Environment},
  url = {https://www.academia.edu/44757497/Assessing_the_Impact_of_Tweets_in_Flood_Events},
  urldate = {2022-12-16},
  abstract = {Social sensing can provide useful information to help detect, manage and solve problems related to people\&\#39;s lifes and physical surroundings. Because of the huge amount of content generated on social media, the problem of social sensing is the},
  file = {/home/yasser/.local/share/Zotero/storage/ZLVJW3AW/Periñán-Pascual - 2020 - Assessing the Impact of Tweets in Flood Events.pdf;/home/yasser/.local/share/Zotero/storage/VCEBYC9K/Assessing_the_Impact_of_Tweets_in_Flood_Events.html}
}

@thesis{petersenIdentificationExplorationExtreme2021,
  title = {Identification and {{Exploration}} of {{Extreme Weather Events From Twitter Data}}},
  author = {Petersen, Julie Maria and Styve, Lise},
  date = {2021},
  institution = {{Linköping University}},
  langid = {english},
  file = {/home/yasser/.local/share/Zotero/storage/GG79L58C/Petersen and Styve - Identification and Exploration of Extreme Weather .pdf}
}

@inproceedings{rehurek_lrec,
  title = {Software Framework for Topic Modelling with Large Corpora},
  booktitle = {Proceedings of the {{LREC}} 2010 Workshop on New Challenges for {{NLP}} Frameworks},
  author = {Řehůřek, Radim and Sojka, Petr},
  date = {2010-05-22},
  pages = {45--50},
  publisher = {{ELRA}},
  location = {{Valletta, Malta}},
  langid = {english}
}

@online{RiverFloodsSweden2022,
  title = {River Floods {{Sweden}}},
  date = {2022-11-06},
  url = {https://www.climatechangepost.com/sweden/river-floods/},
  urldate = {2022-11-17},
  langid = {english},
  organization = {{ClimateChangePost}}
}

@article{romascanuUsingDeepLearning2020,
  title = {Using Deep Learning and Social Network Analysis to Understand and Manage Extreme Flooding},
  author = {Romascanu, Andrei and Ker, Hannah and Sieber, Renee and Greenidge, Sarah and Lumley, Sam and Bush, Drew and Morgan, Stefan and Zhao, Rosie and Brunila, Mikael},
  date = {2020-09},
  journaltitle = {Journal of Contingencies and Crisis Management},
  shortjournal = {J Contingencies and Crisis Management},
  volume = {28},
  number = {3},
  pages = {251--261},
  issn = {0966-0879, 1468-5973},
  doi = {10.1111/1468-5973.12311},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/1468-5973.12311},
  urldate = {2022-09-11},
  langid = {english},
  file = {/home/yasser/.local/share/Zotero/storage/Z36Z3USL/10.1111@1468-5973.12311.pdf.pdf}
}

@misc{saidFloodsDetectionTwitter2020,
  title = {Floods {{Detection}} in {{Twitter Text}} and {{Images}}},
  author = {Said, Naina and Ahmad, Kashif and Gul, Asma and Ahmad, Nasir and Al-Fuqaha, Ala},
  date = {2020-11-30},
  number = {arXiv:2011.14943},
  eprint = {2011.14943},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2011.14943},
  url = {http://arxiv.org/abs/2011.14943},
  urldate = {2022-11-26},
  abstract = {In this paper, we present our methods for the MediaEval 2020 Flood Related Multimedia task, which aims to analyze and combine textual and visual content from social media for the detection of real-world flooding events. The task mainly focuses on identifying floods related tweets relevant to a specific area. We propose several schemes to address the challenge. For text-based flood events detection, we use three different methods, relying on Bog of Words (BOW) and an Italian Version of Bert individually and in combination, achieving an F1-score of 0.77\%, 0.68\%, and 0.70\% on the development set, respectively. For the visual analysis, we rely on features extracted via multiple state-of-the-art deep models pre-trained on ImageNet. The extracted features are then used to train multiple individual classifiers whose scores are then combined in a late fusion manner achieving an F1-score of 0.75\%. For our mandatory multi-modal run, we combine the classification scores obtained with the best textual and visual schemes in a late fusion manner. Overall, better results are obtained with the multimodal scheme achieving an F1-score of 0.80\% on the development set.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/yasser/.local/share/Zotero/storage/95GJCJLF/Said et al. - 2020 - Floods Detection in Twitter Text and Images.pdf;/home/yasser/.local/share/Zotero/storage/WD54PFHS/2011.html}
}

@misc{simonyanVeryDeepConvolutional2015,
  title = {Very {{Deep Convolutional Networks}} for {{Large-Scale Image Recognition}}},
  author = {Simonyan, Karen and Zisserman, Andrew},
  date = {2015-04-10},
  number = {arXiv:1409.1556},
  eprint = {1409.1556},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1409.1556},
  url = {http://arxiv.org/abs/1409.1556},
  urldate = {2022-12-15},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/yasser/.local/share/Zotero/storage/MG2MPMYB/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf;/home/yasser/.local/share/Zotero/storage/NKE6LZD3/1409.html}
}

@article{singhEventClassificationLocation2019,
  title = {Event Classification and Location Prediction from Tweets during Disasters},
  author = {Singh, Jyoti Prakash and Dwivedi, Yogesh K. and Rana, Nripendra P. and Kumar, Abhinav and Kapoor, Kawaljeet Kaur},
  date = {2019-12-01},
  journaltitle = {Annals of Operations Research},
  shortjournal = {Ann Oper Res},
  volume = {283},
  number = {1},
  pages = {737--757},
  issn = {1572-9338},
  doi = {10.1007/s10479-017-2522-3},
  url = {https://doi.org/10.1007/s10479-017-2522-3},
  urldate = {2022-09-07},
  abstract = {Social media is a platform to express one’s view in real time. This real time nature of social media makes it an attractive tool for disaster management, as both victims and officials can put their problems and solutions at the same place in real time. We investigate the Twitter post in a flood related disaster and propose an algorithm to identify victims asking for help. The developed system takes tweets as inputs and categorizes them into high or low priority tweets. User location of high priority tweets with no location information is predicted based on historical locations of the users using the Markov model. The system is working well, with its classification accuracy of 81\%, and location prediction accuracy of 87\%. The present system can be extended for use in other natural disaster situations, such as earthquake, tsunami, etc., as well as man-made disasters such as riots, terrorist attacks etc. The present system is first of its kind, aimed at helping victims during disasters based on their tweets.},
  langid = {english},
  keywords = {Disaster management,Geo-tagging,Location inference,Social media,Twitter},
  file = {/home/yasser/.local/share/Zotero/storage/96N4HL8P/singh2017.pdf.pdf;/home/yasser/.local/share/Zotero/storage/FPHI86KR/Singh et al. - 2019 - Event classification and location prediction from .pdf}
}

@online{SMHI2021,
  title = {{{SMHI}}},
  date = {2021-04-30},
  organization = {{SMHI - Who we are}}
}

@incollection{tehHierarchicalBayesianNonparametric2010,
  title = {Hierarchical {{Bayesian}} Nonparametric Models with Applications},
  booktitle = {Bayesian {{Nonparametrics}}},
  author = {Teh, Yee Whye and Jordan, Michael I.},
  editor = {Holmes, Chris and Hjort, Nils Lid and Müller, Peter and Walker, Stephen G.},
  date = {2010},
  series = {Cambridge {{Series}} in {{Statistical}} and {{Probabilistic Mathematics}}},
  pages = {158--207},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  doi = {10.1017/CBO9780511802478.006},
  url = {https://www.cambridge.org/core/books/bayesian-nonparametrics/hierarchical-bayesian-nonparametric-models-with-applications/0051298A8C5D57586096CDDF02AB1B0F},
  urldate = {2023-01-19},
  abstract = {Hierarchical modeling is a fundamental concept in Bayesian statistics. The basic idea is that parameters are endowed with distributions which may themselves introduce new parameters, and this construction recurses. In this review we discuss the role of hierarchical modeling in Bayesian nonparametrics, focusing on models in which the infinite-dimensional parameters are treated hierarchically. For example, we consider a model in which the base measure for a Dirichlet process is itself treated as a draw from another Dirichlet process. This yields a natural recursion that we refer to as a hierarchical Dirichlet process. We also discuss hierarchies based on the Pitman–Yor process and on completely random processes. We demonstrate the value of these hierarchical constructions in a wide range of practical applications, in problems in computational biology, computer vision and natural language processing.IntroductionHierarchical modeling is a fundamental concept in Bayesian statistics. The basic idea is that parameters are endowed with distributions which may themselves introduce new parameters, and this construction recurses. A common motif in hierarchical modeling is that of the conditionally independent hierarchy, in which a set of parameters are coupled by making their distributions depend on a shared underlying parameter. These distributions are often taken to be identical, based on an assertion of exchangeability and an appeal to de Finetti's theorem.},
  isbn = {978-0-521-51346-3},
  file = {/home/yasser/.local/share/Zotero/storage/YBCZCZ53/Teh and Jordan - 2010 - Hierarchical Bayesian nonparametric models with ap.pdf;/home/yasser/.local/share/Zotero/storage/JZ7BB8DF/0051298A8C5D57586096CDDF02AB1B0F.html}
}

@misc{weerasooriyaKeyXtractTwitterModel2017,
  title = {{{KeyXtract Twitter Model}} - {{An Essential Keywords Extraction Model}} for {{Twitter Designed}} Using {{NLP Tools}}},
  author = {Weerasooriya, Tharindu and Perera, Nandula and Liyanage, S. R.},
  date = {2017-08-09},
  number = {arXiv:1708.02912},
  eprint = {1708.02912},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1708.02912},
  url = {http://arxiv.org/abs/1708.02912},
  urldate = {2022-11-27},
  abstract = {Since a tweet is limited to 140 characters, it is ambiguous and difficult for traditional Natural Language Processing (NLP) tools to analyse. This research presents KeyXtract which enhances the machine learning based Stanford CoreNLP Part-of-Speech (POS) tagger with the Twitter model to extract essential keywords from a tweet. The system was developed using rule-based parsers and two corpora. The data for the research was obtained from a Twitter profile of a telecommunication company. The system development consisted of two stages. At the initial stage, a domain specific corpus was compiled after analysing the tweets. The POS tagger extracted the Noun Phrases and Verb Phrases while the parsers removed noise and extracted any other keywords missed by the POS tagger. The system was evaluated using the Turing Test. After it was tested and compared against Stanford CoreNLP, the second stage of the system was developed addressing the shortcomings of the first stage. It was enhanced using Named Entity Recognition and Lemmatization. The second stage was also tested using the Turing test and its pass rate increased from 50.00\% to 83.33\%. The performance of the final system output was measured using the F1 score. Stanford CoreNLP with the Twitter model had an average F1 of 0.69 while the improved system had a F1 of 0.77. The accuracy of the system could be improved by using a complete domain specific corpus. Since the system used linguistic features of a sentence, it could be applied to other NLP tools.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {/home/yasser/.local/share/Zotero/storage/9UEPNTUL/Weerasooriya et al. - 2017 - KeyXtract Twitter Model - An Essential Keywords Ex.pdf;/home/yasser/.local/share/Zotero/storage/4BIC6ILT/1708.html}
}

@inproceedings{zhouLearningDeepFeatures2014,
  title = {Learning {{Deep Features}} for {{Scene Recognition}} Using {{Places Database}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Zhou, Bolei and Lapedriza, Agata and Xiao, Jianxiong and Torralba, Antonio and Oliva, Aude},
  date = {2014},
  volume = {27},
  publisher = {{Curran Associates, Inc.}},
  url = {https://papers.nips.cc/paper/2014/hash/3fe94a002317b5f9259f82690aeea4cd-Abstract.html},
  urldate = {2022-12-15},
  abstract = {Scene recognition is one of the hallmark tasks of computer vision, allowing definition of a context for object recognition. Whereas the tremendous recent progress in object recognition tasks is due to the availability of large datasets like ImageNet and the rise of Convolutional Neural Networks (CNNs) for learning high-level features, performance at scene recognition has not attained the same level of success. This may be because current deep features trained from ImageNet are not competitive enough for such tasks. Here, we introduce a new scene-centric database called Places with over 7 million labeled pictures of scenes. We propose new methods to compare the density and diversity of image datasets and show that Places is as dense as other scene datasets and has more diversity. Using CNN, we learn deep features for scene recognition tasks, and establish new state-of-the-art results on several scene-centric datasets. A visualization of the CNN layers' responses allows us to show differences in the internal representations of object-centric and scene-centric networks.},
  file = {/home/yasser/.local/share/Zotero/storage/WZJZPX3X/Zhou et al. - 2014 - Learning Deep Features for Scene Recognition using.pdf}
}
