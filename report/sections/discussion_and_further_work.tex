% vim: spell spelllang=en_gb
\chapter{Discussion and Further Work}\label{sec:discussion_and_further_work}

This section discusses the results of the methods used and their reliability in addressing the
research questions mentioned in the introduction section while suggesting improvements to enhance
the results.

The more tweets obtained for an event, the more information can be extracted about it, and the
results of the experiments show that some flood events have more tweets than others; one possible
reason is that these events are more impactful on society, causing them to attract the attention of
the affected citizens. One limitation of this approach is that some events happen without getting
reported because they are either out of sight from the public eye, or didn't attract sufficient
attention. Social media won't provide sufficient data, if any, about these events to process;
integrating more data sources into the pipeline, such as meteorological data, reports from
governmental agencies, \ac{GDELT}\footnote{https://www.gdeltproject.org/}, and other social media
might supplement this deficiency. The pre-processing used filters out tweets with the same text
verbatim, leaving out near-identical tweets generated by bots for malicious or utility purposes (e.g. acting
as a feed generator). Some users post tweets that are flood-relevant yet fake to provide the public
with misleading information for malicious reasons, polluting the data in the process. One potential
improvement to the pipeline is to include methods to detect and filter out fake news to preserve the
integrity of the data. Another approach is to blacklist user accounts with suspicious activities in
their past tweets and network. 

The evaluation metrics for the classifier based on the DistilBERT transformer seem promising on the
training datasets, with an accuracy of 92.31\% and F$_{1}$ score of 91.81\%; yet, the experiments
show that the model has high precision and low recall. The nature of the text in tweets makes it
more difficult for them to get classified. The tweets are microblogs (i.e. small text documents),
where there is not enough context in the tweets to classify them correctly (e.g. ``It's wet in
location X'', and ``It rained a lot yesterday''); also, since the context of the tweets includes
other elements than text, such as emojis, images, hashtags, and \ac{URL}s, the classifier will not
be able to indicate the actual intent of the user, failing in categorizing the tweet correctly (e.g.
It's very wet here https://t.co/PcroA3s1A2). Introducing these elements into the classification
process would increase the algorithm's accuracy, which is possible with images and \ac{URL}s, by
using an image classifier and a web scraper. The language of the text is another aspect of the data
that impacts the model's accuracy, since the classifier works only on English text, forcing the
translation step on the data, reducing their quality, and ultimately impacting the performance of
the trained model. One way to mitigate this problem is to remove the translation step and use a
classifier that accepts Swedish text.

The pipeline identifies the locations of the events used in the experiments by showing a high
frequency of tweets mentioning the location using the plots. Yet, it failed to identify the correct
geographical locations for some keywords, such as Spain and Turkey; this is because some terms can
refer to multiple locations existing in the world, and one method to identify the intended location
within the tweet is by generating a confidence score using several factors, such as the
``importance''\footnote{https://nominatim.org/release-docs/develop/customize/Importance/} attribute
obtained from the Nominatim package. Another improvement to the location extraction step would be
using a better way to handle the existence of several locations in one tweet instead of picking the
one with the smallest parameter only.

The plots in the visual interface present the tweets' textual, spatial, and temporal aspects
interactively. The map shows the distribution of the geographical locations mentioned in the tweet
and enables filtering using regions; yet, the map does not allow box or lasso selections, and the
pop-up of the pointers shows the name of the location only, where it could be more informative by
including more information related to the tweet (e.g. text and date created). The histogram shows
the temporal distribution for the creation date of the tweets, where the number of tweets is the
highest at the start of the event then it reduces gradually afterwards. This information can be a
factor in calculating the impact of the flood on society since the event attracts more attention the
more it influences the citizens. The tweets table provides a way to check some features of the
selected tweets, and it could be improved by adding a text filter to focus on tweets that contain
specific terms; this feature would support the ``Filter'' task for the textual data. The test cases
show a potential use case for textual filtering by limiting the tweets to the terms related to
trends found by exploring the clusters in the \ac{t-SNE} scatter plot, such as traffic disruption
and \ac{SMHI} warnings. The clustered 2-dimensional space provides a method to find similar tweets
using their spatial proximity, potentially referring to similar events, assessed using the
spatio-temporal distribution in the map and histogram plots. Besides these trends, the results of
the text analysis techniques shown in the \ac{t-SNE}'s scatter plot, \ac{LDA} table, and \ac{TF-IDF}
table didn't provide any insights due to the nature of the text. Using other clustering techniques
in the scatter plot, such as K-means, might bring better results. Obtaining more data and changing
the pre-processing approach might improve the results of these techniques. More text analysis
techniques can be used, such as sentiment analysis, which gives the ability to quantify the impact
of the event.

Further work can include the following:
\begin{itemize}
  \item Applying the pipeline to other type of events, such as earthquakes, by changing the query
    and the training dataset for the classifier.
  \item Applying the pipeline to other countries by changing the map used in the visualization.
  \item Using streaming for live event detection to identify flood events by using some criterion,
    such as sudden bursts of tweets talking about flooding.
  \item Augmenting warning systems pipeline by including this project's pipeline to detect and visualize flood events.
\end{itemize}
