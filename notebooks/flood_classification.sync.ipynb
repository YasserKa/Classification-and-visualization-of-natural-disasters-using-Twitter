{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbead18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from huggingface_hub import notebook_login\n",
    "from hydra import compose, initialize\n",
    "from hydra.utils import to_absolute_path as abspath\n",
    "from omegaconf import DictConfig\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers.models.auto.modeling_auto import AutoModelForSequenceClassification\n",
    "from transformers.models.auto.tokenization_auto import AutoTokenizer\n",
    "from transformers.trainer import Trainer\n",
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "from src.data.text_processing import TextProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4abd9",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "Loading available datasets and  transforming it to pandas dataframe with columns\n",
    "`text` and `label`, where the label shows if the text is on-topic (1) or\n",
    "off-topic (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf8ccc",
   "metadata": {},
   "source": [
    "Data obtained from the supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa7c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg: DictConfig = compose(config_name=\"config\")\n",
    "    supervisor_tweets_path = abspath(\"../\" + cfg.supervisor.tweets)\n",
    "    alberta_path = abspath(\"../\" + cfg.alberta.raw)\n",
    "    queensland_path = abspath(\"../\" + cfg.queensland.raw)\n",
    "\n",
    "with open(supervisor_tweets_path, \"r\") as file:\n",
    "    tweets_json = json.load(file)\n",
    "supervisor_df = pd.json_normalize(list(tweets_json.values()))\n",
    "print(supervisor_df.shape)\n",
    "# NOTE: Some tweets, don't have geo-tagging or attachements, hence the NaN values\n",
    "supervisor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_df = supervisor_df[[\"id\", \"text_en\", \"On Topic\"]]\n",
    "supervisor_df = supervisor_df.rename(columns={\"text_en\": \"text\", \"On Topic\": \"label\"})\n",
    "supervisor_df = supervisor_df[supervisor_df[\"label\"] != \"\"]\n",
    "supervisor_df = supervisor_df.astype({\"label\": \"int\", \"id\": \"int\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b6fde",
   "metadata": {},
   "source": [
    "Data obtaine from [CrisisLex: Download Crisis-Related Collections](https://crisislex.org/data-collections.html#CrisisLexT6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "queensland_df = pd.read_csv(queensland_path)\n",
    "alberta_df = pd.read_csv(alberta_path)\n",
    "\n",
    "print(f\"queensland {queensland_df.shape}\")\n",
    "print(f\"alberta {alberta_df.shape}\")\n",
    "# NOTE: Some tweets, don't have geo-tagging or attachements, hence the NaN values\n",
    "queensland_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1769011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_crisislex_data(df):\n",
    "    df = df.rename(columns={\"tweet_id\": \"id\", \"tweet\": \"text\"})\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda x: 1 if x == \"on-topic\" else 0)\n",
    "    df[\"id\"] = df[\"id\"].apply(lambda x: x[1:-1])\n",
    "    df = df.astype({\"id\": \"int\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "queensland_df = process_crisislex_data(queensland_df)\n",
    "alberta_df = process_crisislex_data(alberta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6c1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_needed = pd.concat([queensland_df, alberta_df, supervisor_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958abd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove retweets\n",
    "df_needed = df_needed[df_needed[\"text\"].str[:2] != \"RT\"]\n",
    "# Remove duplicates\n",
    "df_needed = df_needed.drop_duplicates()\n",
    "\n",
    "text_preprocessing = TextProcessing()\n",
    "# Clean text\n",
    "df_needed[\"text\"] = text_preprocessing.clean_text(df_needed[\"text\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_needed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df_needed)\n",
    "\n",
    "dataset = dataset.remove_columns([\"id\"])\n",
    "\n",
    "train_testvalid = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n",
    "\n",
    "train_test_valid_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_testvalid[\"train\"],\n",
    "        \"test\": test_valid[\"test\"],\n",
    "        \"valid\": test_valid[\"train\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3681115f",
   "metadata": {},
   "source": [
    "## Finetuning the model\n",
    "\n",
    "Use hugging face library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8177a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_labels = 2\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt, num_labels=num_labels\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "train_test_valid_dataset_tokenized = train_test_valid_dataset.map(\n",
    "    tokenize, batched=True, batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f24b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "logging_steps = len(train_test_valid_dataset_tokenized[\"train\"]) // batch_size\n",
    "model_name = \"bert-base-uncased-finetuned-floods\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=True,\n",
    "    log_level=\"error\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_test_valid_dataset_tokenized[\"train\"],\n",
    "    eval_dataset=train_test_valid_dataset_tokenized[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
